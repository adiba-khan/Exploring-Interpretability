#import libraries
import os
import xgboost as xgb
from xgboost.sklearn import XGBClassifier
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, roc_curve, auc
from scipy import interp
%matplotlib inline

import sklearn
import sklearn.datasets
import sklearn.ensemble
import numpy as np
import lime
import lime.lime_tabular
from __future__ import print_function
np.random.seed(1)

#remove columns as noted in readmissions tutorial, but we will use OHE code from LIME
MICU_admits_clean = pd.read_csv('MICU_admits_clean.csv')
MICU_processed = MICU_admits_clean.drop(['subject_id','hadm_id','admittime','dischtime','first_careunit','last_careunit','readmit_dt','readmit_last_careunit', 'next_readmit_dt'], axis = 1)

#change pandas data frame to numpy array
data = MICU_processed.values

#encode categorical features
feature_names = ['age', 'gender', 'marital_status', 'insurance', 'urea_n_min', 'urea_n_max', 'urea_n_mean', 'platelets_min',
                 'platelets_max', 'platelets_mean', 'magnesium_max', 'albumin_min', 'calcium_min', 'resprate_min', 'resprate_max',
                 'resprate_mean', 'glucose_min', 'glucose_max', 'glucose_mean', 'hr_min', 'hr_max', 'hr_mean', 'sysbp_min',
                 'sysbp_max', 'sysbp_mean', 'diasbp_min', 'diasbp_max', 'diasbp_mean', 'temp_min', 'temp_max', 'temp_mean',
                 'sapsii', 'sofa', 'future_readmit']

labels = data[:,33] #changed column no. for MIMIC data
le= sklearn.preprocessing.LabelEncoder()
le.fit(labels)
labels = le.transform(labels)
class_names = le.classes_
data = data[:,:-1]

categorical_features = [1, 2, 3]

categorical_names = {}
for feature in categorical_features:
    le = sklearn.preprocessing.LabelEncoder()
    le.fit(data[:, feature])
    data[:, feature] = le.transform(data[:, feature])
    categorical_names[feature] = le.classes_

data = data.astype(float)

encoder = sklearn.preprocessing.OneHotEncoder(categorical_features=categorical_features)

np.random.seed(1)
train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(data, labels, train_size=0.80)

encoder.fit(data)
encoded_train = encoder.transform(train)

import xgboost
gbtree = xgboost.XGBClassifier(n_estimators=300, max_depth=5)
gbtree.fit(encoded_train, labels_train)

sklearn.metrics.accuracy_score(labels_test, gbtree.predict(encoder.transform(test)))

predict_fn = lambda x: gbtree.predict_proba(encoder.transform(x)).astype(float)

explainer = lime.lime_tabular.LimeTabularExplainer(train ,feature_names = feature_names,class_names=class_names,
                                                   categorical_features=categorical_features,
                                                   categorical_names=categorical_names, kernel_width=3)

#need to generate evaluation metrics for project: run time, algorithmic complexity
#can we generate other graphs besides visuals below?

#---------------------------------------------------------
#Run examples for visual predictor in Jupyter notebooks
#---------------------------------------------------------

np.random.seed(1)
i = 49
exp = explainer.explain_instance(test[i], predict_fn, num_features=5)
exp.show_in_notebook(show_all=False)

i = 10
exp = explainer.explain_instance(test[i], predict_fn, num_features=5)
exp.show_in_notebook(show_all=False)

test[10]
